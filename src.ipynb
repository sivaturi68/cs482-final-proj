{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optical Flow Trajectory Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/d1rtys0ck/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2024-5-4 Python-3.10.12 torch-2.3.0+cu121 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "    <style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"c895010d-2b78-4dc2-9191-21863509e70a\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "'use strict';\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    function drop(id) {\n      const view = Bokeh.index.get_by_id(id)\n      if (view != null) {\n        view.model.document.clear()\n        Bokeh.index.delete(view)\n      }\n    }\n\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n\n    // Clean up Bokeh references\n    if (id != null) {\n      drop(id)\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim()\n            drop(id)\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded(error = null) {\n    const el = document.getElementById(\"c895010d-2b78-4dc2-9191-21863509e70a\");\n    if (el != null) {\n      const html = (() => {\n        if (typeof root.Bokeh === \"undefined\") {\n          if (error == null) {\n            return \"BokehJS is loading ...\";\n          } else {\n            return \"BokehJS failed to load.\";\n          }\n        } else {\n          const prefix = `BokehJS ${root.Bokeh.version}`;\n          if (error == null) {\n            return `${prefix} successfully loaded.`;\n          } else {\n            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n          }\n        }\n      })();\n      el.innerHTML = html;\n\n      if (error != null) {\n        const wrapper = document.createElement(\"div\");\n        wrapper.style.overflow = \"auto\";\n        wrapper.style.height = \"5em\";\n        wrapper.style.resize = \"vertical\";\n        const content = document.createElement(\"div\");\n        content.style.fontFamily = \"monospace\";\n        content.style.whiteSpace = \"pre-wrap\";\n        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n        content.textContent = error.stack ?? error.toString();\n        wrapper.append(content);\n        el.append(wrapper);\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(() => display_loaded(error), 100);\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.4.1.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n      try {\n            for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n\n      } catch (error) {display_loaded(error);throw error;\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"c895010d-2b78-4dc2-9191-21863509e70a\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import numpy.linalg as npl\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import cv2 as cv\n",
    "from typing import List, Tuple\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import bokeh\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "import torch\n",
    "#Import yolov5 for object detection/tracking\n",
    "from yolov5 import YOLOv5\n",
    "PROJECT_DEBUG = True\n",
    "%matplotlib inline\n",
    "\n",
    "#Switch to CUDA if we have a GPU we can use\n",
    "yolo_pre_train_model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOLO requires colors in images\n",
    "def load_image_color(filepath: str) -> np.ndarray:\n",
    "    im = cv.imread(filepath, cv.IMREAD_COLOR)\n",
    "    if im is None:\n",
    "        raise FileNotFoundError(f\"Image not found at {filepath}\")\n",
    "    im = cv.cvtColor(im, cv.COLOR_BGR2RGB)\n",
    "    return im.astype(np.float32) / 255.0 \n",
    "\n",
    "def load_image_gray(filepath: str) -> np.ndarray:\n",
    "    img = cv.imread(filepath, cv.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"Image not found at {filepath}\")\n",
    "    mi = np.min(img)\n",
    "    ma = np.max(img)\n",
    "    return img / float(ma - mi)\n",
    "\n",
    "def parse_meta(folder: str) -> Tuple[int, int, int, int]:\n",
    "    supported_types = ['png', 'txt']\n",
    "    all_files = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))]\n",
    "    supported_files = [f for f in all_files if any([f.endswith(end) for end in supported_types])]\n",
    "\n",
    "    num_frames: int = 0\n",
    "    frame_width: int = 0\n",
    "    frame_height: int = 0\n",
    "    frame_rate: int = 0\n",
    "\n",
    "    if 'meta.txt' not in supported_files:\n",
    "        raise FileNotFoundError(f'meta.txt not found in {folder}')\n",
    "    else:\n",
    "        with open(os.path.join(folder, 'meta.txt'), 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            if len(lines) < 4:\n",
    "                raise Exception(f'Not enough lines in meta.txt')\n",
    "            frame_width, frame_height, num_frames, frame_rate = (int(line) for line in lines[:4])\n",
    "\n",
    "    return (frame_width, frame_height, num_frames, frame_rate)\n",
    "\n",
    "def load_image_sequence(folder: str, color: bool = False) -> np.ndarray:\n",
    "    supported_types = ['png', 'txt']\n",
    "    all_files = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))]\n",
    "    supported_files = [f for f in all_files if any([f.endswith(end) for end in supported_types])]\n",
    "    unsupported_files = [f for f in all_files if f not in supported_files]\n",
    "\n",
    "    if PROJECT_DEBUG:\n",
    "        if unsupported_files != []:\n",
    "            print(f'Warning! Following files from {folder} are unsupported, ignoring: {\", \".join(unsupported_files)}')\n",
    "\n",
    "    num_frames: int = 0\n",
    "    frame_width: int = 0\n",
    "    frame_height: int = 0\n",
    "    frame_rate: int = 0\n",
    "\n",
    "    frame_width, frame_height, num_frames, frame_rate = parse_meta(folder)\n",
    "\n",
    "    if num_frames == 0:\n",
    "        raise Exception(f'Folder must have at least one frame')\n",
    "    if frame_width == 0 or frame_height == 0:\n",
    "        raise Exception(f'Dimensions must result in non-zero number of pixels')\n",
    "\n",
    "    image_files = [f for f in all_files if f.endswith('png')]\n",
    "\n",
    "    if len(image_files) < num_frames:\n",
    "        raise FileNotFoundError(f'Not enough files for number of frames specified in meta.txt ({len(image_files)} < {num_frames})')\n",
    "\n",
    "    if not color:\n",
    "        video = np.zeros((num_frames, frame_height, frame_width))\n",
    "    else:\n",
    "        video = np.zeros((num_frames, frame_height, frame_width, 3), dtype=np.float32)\n",
    "        \n",
    "\n",
    "    load_function = load_image_color if color else load_image_gray\n",
    "\n",
    "    if len(image_files) == 0:\n",
    "        raise FileNotFoundError()\n",
    "\n",
    "    for f_no, img_file in enumerate(image_files):\n",
    "        video[f_no] = load_function(os.path.join(folder, img_file))\n",
    "\n",
    "    if video is None:\n",
    "        print(\"Failed to load\")\n",
    "\n",
    "    return video\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "convolve = lambda img, flt: scipy.ndimage.convolve(img, flt, mode='nearest')\n",
    "\n",
    "def horiz_deriv(video: np.ndarray):\n",
    "    filt = np.array([\n",
    "        [[-1, 0, 1],\n",
    "         [-2, 0, 2],\n",
    "         [-1, 0, 1]],\n",
    "        [[-2, 0, 2],\n",
    "         [-4, 0, 4],\n",
    "         [-2, 0, 2]],\n",
    "        [[-1, 0, 1],\n",
    "         [-2, 0, 2],\n",
    "         [-1, 0, 1],]\n",
    "    ])\n",
    "\n",
    "    return convolve(video, filt)\n",
    "\n",
    "def vert_deriv(video: np.ndarray):\n",
    "    filt = np.array([\n",
    "        [[-1, -2, -1],\n",
    "         [0, 0, 0],\n",
    "         [1, 2, 1]],\n",
    "        [[-2, -4, -2],\n",
    "         [0, 0, 0],\n",
    "         [2, 4, 2]],\n",
    "        [[-1, -2, -1],\n",
    "         [0, 0, 0],\n",
    "         [1, 2, 1]],\n",
    "    ])\n",
    "\n",
    "    return convolve(video, filt)\n",
    "\n",
    "def time_deriv(video: np.ndarray):\n",
    "    filt = np.array([\n",
    "        [[-1, -2, -1],\n",
    "         [-2, -4, -2],\n",
    "         [-1, -2, -1]],\n",
    "        [[0, 0, 0],\n",
    "         [0, 0, 0],\n",
    "         [0, 0, 0]],\n",
    "        [[1, 2, 1],\n",
    "         [2, 4, 2],\n",
    "         [1, 2, 1]],\n",
    "    ])\n",
    "\n",
    "    return convolve(video, filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = './other_tests/dumptruck/'\n",
    "# folder = './blender_tests/throw1/mist/'\n",
    "\n",
    "video = load_image_sequence(folder)\n",
    "frame_width, frame_height, num_frames, frame_rate = parse_meta(folder)\n",
    "\n",
    "I_x = horiz_deriv(video)\n",
    "I_y = vert_deriv(video)\n",
    "I_t = time_deriv(video)\n",
    "\n",
    "for deriv in I_t:\n",
    "    plt.figure()\n",
    "    plt.imshow(deriv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f4e1af41840>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_frame = video[0]\n",
    "mask1 = np.zeros_like(first_frame)\n",
    "mask1[:, 650:850] = 1\n",
    "mask2 = np.zeros_like(first_frame)\n",
    "mask2[100:200, :] = 1\n",
    "\n",
    "mask = np.logical_and(mask1, mask2).astype(np.uint8)\n",
    "\n",
    "track_points = cv.goodFeaturesToTrack(\n",
    "    first_frame.astype('f4'),\n",
    "    maxCorners=100,\n",
    "    qualityLevel=0.1,\n",
    "    minDistance=7,\n",
    "    blockSize=7,\n",
    "    mask=None)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(first_frame, cmap='gray', vmin=-1, vmax=1)\n",
    "plt.scatter(track_points[:, 0, 0], track_points[:, 0, 1], marker='.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4e1af7e950>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WINDOW_SIZE = 5\n",
    "\n",
    "def get_window_coordinates(center: Tuple[int, int], win_size: int, lower_clamp=True) -> List[Tuple[int, int]]:\n",
    "    xs = [x for x in range(center[0] - win_size // 2, center[0] + win_size // 2 + 1) if (not lower_clamp) or (x >= 0)]\n",
    "    ys = [y for y in range(center[1] - win_size // 2, center[1] + win_size // 2 + 1) if (not lower_clamp) or (y >= 0)]\n",
    "\n",
    "    coords = [(x, y) for x in xs for y in ys]\n",
    "    return coords\n",
    "\n",
    "frame1 = video[0]\n",
    "frame2 = video[1]\n",
    "\n",
    "u_field = np.zeros_like(frame1)\n",
    "v_field = np.zeros_like(frame1)\n",
    "zeroes = np.zeros_like(frame1)\n",
    "\n",
    "l = 0.01\n",
    "\n",
    "# while True:\n",
    "for i in range(100):\n",
    "    calculation = (I_x[0] * u_field + I_y[0] * v_field + I_t[0]) / ((1 / l) + I_x[0] ** 2 + I_y[0] ** 2)\n",
    "    u_field -= calculation * I_x[0]\n",
    "    v_field -= calculation * I_y[0]\n",
    "\n",
    "x, y = np.meshgrid(np.arange(frame1.shape[0]), np.arange(frame1.shape[1]))\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(np.stack((u_field, v_field, zeroes), axis=2), vmin=-1, vmax=1)\n",
    "# plt.quiver(x[::10], y[::10], u_field[::10, ::10], v_field[::10, ::10], color='r')\n",
    "# plt.figure()\n",
    "# plt.imshow(v_field, vmin=-1, vmax=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
